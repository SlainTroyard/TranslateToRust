#!/bin/bash
# Example script to set up environment variables for LLM API access
# Copy this file to setup_env.sh, update the values, and run with source setup_env.sh

# 基础配置
# ====================
# 选择提供商: OpenAI, Anthropic, GoogleAI, Local
export LLM_PROVIDER="OpenAI"

# API密钥
export LLM_API_KEY="your-api-key-here"

# API URL
export LLM_API_URL="https://api.openai.com/v1/chat/completions"

# 默认模型
export LLM_DEFAULT_MODEL="gpt-4"

# 模型参数 (JSON格式)
# ====================
# 可以在运行时用命令行参数覆盖这些值
export LLM_MODEL_PARAMS='{
  "temperature": 0.2,
  "max_tokens": 4000,
  "top_p": 1.0,
  "frequency_penalty": 0.0,
  "presence_penalty": 0.0
}'

# 自定义HTTP头 (JSON格式)
# ====================
export LLM_HEADERS='{
  "content-type": "application/json"
}'

# 模型提示词配置
# ====================
# 系统消息前缀 (仅对支持系统消息的模型有效)
export LLM_SYSTEM_MESSAGE="You are a C/C++ to Rust code translator expert. Your task is to translate code accurately while using idiomatic Rust patterns."

echo "LLM 环境变量已设置:"
echo "Provider: $LLM_PROVIDER"
echo "API URL: $LLM_API_URL"
echo "Default Model: $LLM_DEFAULT_MODEL"
echo "Temperature: $(echo $LLM_MODEL_PARAMS | grep -o '"temperature": [0-9.]*' | cut -d ' ' -f2)"
echo "Max tokens: $(echo $LLM_MODEL_PARAMS | grep -o '"max_tokens": [0-9]*' | cut -d ' ' -f2)" 